---
title: "Logistic Regression Models & Results"
author: "Jonathan Olds"
date: "11/9/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
'%!in%' <- function(x,y)!('%in%'(x,y))
```

## Loading and Prepping Data
```{r load prep data}
  batters = read_csv("BattersData.csv")
  pitchers = read_csv("PitchersData.csv")
  
  # Removing 2008 & 2009 seasons - no list 
  batters = batters %>% filter(Season>=2010)
  pitchers = pitchers %>% filter(Season >= 2010)
  
  # Creating Test & Train data for batters
  set.seed(2020)
  batters$Top100 = as.factor(batters$Top100)
  batters_pi = unique(batters$playerid)
  batters_piselections = batters_pi[createDataPartition(y = batters_pi, p = 0.7, list = FALSE)]  
  batters_train = batters[which(batters$playerid %in% batters_piselections),]
  batters_test = batters[which(batters$playerid %!in% batters_piselections),]
  which(batters$Name %in% batters_train & batters$Name %in% batters_test)
  
  # Create Test & Train data for pitchers
  set.seed(2020)
  pitchers$Top100 = factor(pitchers$Top100)
  pitchers_pi = unique(pitchers$playerid)
  pitchers_piselections = pitchers_pi[createDataPartition(y = pitchers_pi, p = 0.7, list = FALSE)]  
  pitchers_train = pitchers[which(pitchers$playerid %in% pitchers_piselections),]
  pitchers_test = pitchers[which(pitchers$playerid %!in% pitchers_piselections),]  
  which(pitchers$Name %in% pitchers_train & pitchers$Name %in% pitchers_test)
  
  # Dataframe of only pca-eligible variables - batters
  batters_active = batters[,c(88:167)]
  batters_active = batters_active[,which(apply(batters_active, 2, sd) != 0)]
  
  # Dataframe of only pca-eligible variables - pitchers
  pitchers_active = pitchers[,74:140]
  pitchers_active = pitchers_active[,which(apply(pitchers_active, 2, sd) != 0)]
  
  # Function to calculate test accuracy
  calc_accuracy_function = function(actual, predicted) {
    mean(actual == predicted)
  }

```

## Traditional PCA & LR - Batters
 Variables Included - Hits, Walks, Strikeouts, Doubles, Triples, Home Runs, Total Bases, Runs Batted In, Batting Average, On Base Percentage, Slugging Percentage, On Base + Slugging, Stolen Bases, Caught Stealing, Runs Created per Game, Putouts, Assists, Errors, Double Plays, Fielding Percentage, Range Factor/9 Innings, All Star, Gold Glove, Silver Slugger, MVP Rank & Vote Points, Rookie of the Year Rank & Vote Points
```{r traditional batters, cache = TRUE}
  # Selecting variables
  batters_traditional = batters_active[,c(4:15,46:47,31,57:62,68:72,75:76)]
  # PCA 
  pca_batters_traditional = prcomp(batters_traditional, scale. = TRUE)
  summary(pca_batters_traditional)
  cbind(batters[1:6,1],pca_batters_traditional$x[1:6,1:6])
  head(pca_batters_traditional$scale^2, n = 6)
  # Assigning two elements of variability to vectors
  PVE = summary(pca_batters_traditional)$importance[2,]
  CVE = summary(pca_batters_traditional)$importance[3,]
  
  # Graph of variability explained
  PVEplot <- qplot(c(1:20), PVE[1:20]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("PVE - Batters") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.1))
  PVEplot
  # Flattens out after the 17th PCA component
  
  #Graph of cumulative variance explained
  CVEplot <- qplot(c(1:20), CVE[1:20]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("CVE - Batters") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.2)) + 
    geom_hline(yintercept = 0.95, color = "red", lwd = 1)
  CVEplot
  # Reaches 95% cumulative variability after 16th component
  
  # Adding pca components and descriptive values to dataset
  batters_traditional = cbind(batters_traditional, pca_batters_traditional$x[,1:16])
  batters_traditional = cbind(batters[,c(1:6,190:193)], batters_traditional)
  
  # Dividing into test and train
  batters_train = batters_traditional[which(batters_traditional$playerid %in% batters_piselections),]
  batters_test = batters_traditional[which(batters_traditional$playerid %!in% batters_piselections),]
  
  # Logistic regression model
  set.seed(2020)
  batters_glm_traditional = train(
    form = Top100 ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + 
      PC12 + PC13 + PC14 + PC15 + PC16,
    data = batters_train,
    trControl = trainControl(method = "cv", number = 10),
    method = "glm",
    family = "binomial"
  )
  
  # Model summary
  batters_glm_traditional
  # Model values
  batters_glm_traditional$finalModel
  
  # Test data accuracy
  calc_accuracy_function(batters_test$Top100,
                         predict(batters_glm_traditional, newdata = batters_test))
  
  # Dataset of predictions v actual
  batterscomp_traditional = cbind(batters_train$Name, predict(batters_glm_traditional, 
                                                  newdata = batters_train, 
                                                  type = "prob"), batters_train$Top100)
  head(batterscomp_traditional)
  
  # Confusion matrix
  batters_cm_trad = confusionMatrix(predict(batters_glm_traditional,newdata = batters_test), batters_test$Top100, positive='1')
  batters_cm_trad$table
```
## Traditional PCA & LR - Pitchers
 Variables Included - Wins, Losses, Complete Games, Shutouts, Saves, Hits, Runs, Earned Runs, Earned Run Average, Walks + Hits/Innings Pitched, Run Support Per 9, Home Runs Per 9, Walks Per 9, Strikeouts Per 9, Runs Against Per 9, All Star, Gold Glove, Silver Slugger, MVP Rank and Vote Points, Cy Young Rank and Vote Points, Rookie of the Year Rank and Vote Points
```{r traditional pitchers, cache = TRUE}
  # Selecting variables
  pitchers_traditional = pitchers_active[,c(1:2,5:7,13:18,20:23,50:54,57:58,61:62)]
  # PCA 
  pca_pitchers_traditional = prcomp(pitchers_traditional, scale. = TRUE)
  summary(pca_pitchers_traditional)
  cbind(pitchers[1:6,1],pca_pitchers_traditional$x[1:6,1:6])
  head(pca_pitchers_traditional$scale^2, n = 6)
  # Assigning elements of variability to vectors
  PVE = summary(pca_pitchers_traditional)$importance[2,]
  CVE = summary(pca_pitchers_traditional)$importance[3,]
  
  # Graph of variability explained
  PVEplot <- qplot(c(1:20), PVE[1:20]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("PVE - pitchers") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.1))
  PVEplot
  # Flattens out after the 17th PCA component
  
  # Graph of cumulative variance explained
  CVEplot <- qplot(c(1:20), CVE[1:20]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("CVE - pitchers") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.2)) + 
    geom_hline(yintercept = 0.95, color = "red", lwd = 1)
  CVEplot
  # Reaches 95% cumulative variability after 16th component
  
  # Adding PCA components and descriptive statistics to dataset
  pitchers_traditional = cbind(pitchers_traditional, pca_pitchers_traditional$x[,1:16])
  pitchers_traditional = cbind(pitchers[,c(1:6,163:166)], pitchers_traditional)
  
  # Dividing into test and train
  pitchers_train = pitchers_traditional[which(pitchers_traditional$playerid %in% pitchers_piselections),]
  pitchers_test = pitchers_traditional[which(pitchers_traditional$playerid %!in% pitchers_piselections),]

  # Logistic Regression Model
  set.seed(2020)
  pitchers_glm_traditional = train(
    form = Top100 ~ PC1 + PC2,
    data = pitchers_train,
    trControl = trainControl(method = "cv", number = 10),
    method = "glm",
    family = "binomial"
  )
  
  # Model summary
  pitchers_glm_traditional
  # Model values
  pitchers_glm_traditional$finalModel
  
  # Test accuracy
  calc_accuracy_function(pitchers_test$Top100,
                         predict(pitchers_glm_traditional, newdata = pitchers_test))
  
  # Dataset measuring predictions vs accuracy
  pitcherscomp_traditional = cbind(pitchers_train$Name, predict(pitchers_glm_traditional, 
                                                  newdata = pitchers_train, 
                                                  type = "prob"), pitchers_train$Top100)
  head(pitcherscomp_traditional)

  # Confusion Matrix
  pitchers_cm_trad = confusionMatrix(predict(pitchers_glm_traditional, newdata = pitchers_test),pitchers_test$Top100, positive = '1')
  pitchers_cm_trad$table
```
  
## Advanced PCA & LR - Batters
Variables Included - Batting Average on Balls in Play, Line Drive Percentage, Ground Ball Percentage, Fly Ball Percentage, Home Runs per Fly Ball, Pull Percent, Center Percent, Opposite Field Percent, Soft Contact Percent, Medium Contact Percent, Hard Contact Percent, Walks per Strikeout, weighted On Base Average, On Base Plus Slugging Plus, weighted Runs Created Plus, Batting Wins (BR), Wins Above Average, WAR (BR), oWAR (BR), WAR (FG), Runs Expectancy Wins, Win Probability Added, Player Leverage Index, Win Probability Added Per Leverage, Clutch, Offensive Winning Percentage, Batting Wins (FG), oWAR (FG), Ultimate Base Running, weighted Grounded into Double Plays, weighted Stolen Bases, Base Running Runs, Defensive Runs Saved (BR), Runs Saved on Good Plays, dWAR (BR), DRS (FG), dWAR (FG), All Star, Gold Glove, Silver Slugger, MVP Rank & Voting Points, Rookie of the Year Rank & Voting Points
```{r advanced batters, cache = TRUE}
  # Selecting Variables
  batters_advanced = batters_active[,c(16:29,32:45,48:51,63:72,75:76)]
  # PCA
  pca_batters_advanced = prcomp(batters_advanced, scale. = TRUE)
  summary(pca_batters_advanced)
  cbind(batters[1:6,1],pca_batters_advanced$x[1:6,1:6])
  head(pca_batters_advanced$scale^2, n = 6)
  # Assigning elements of variability to vectors
  PVE = summary(pca_batters_advanced)$importance[2,]
  CVE = summary(pca_batters_advanced)$importance[3,]
  
  # Graph of variability explained
  PVEplot <- qplot(c(1:25), PVE[1:25]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("PVE - Batters") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.1))
  PVEplot
  # Flattens out after the 18th PCA component
  
  # Graph of cumulative variability explained
  CVEplot <- qplot(c(1:25), CVE[1:25]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("CVE - Batters") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.2)) + 
    geom_hline(yintercept = 0.95, color = "red", lwd = 1)
  CVEplot
  # Reaches 95% cumulative variability after 23rd component
  
  # Adding PCA components and descriptive statistics back to dataset
  batters_advanced = cbind(batters_advanced, pca_batters_advanced$x[,1:23])
  batters_advanced = cbind(batters[,c(1:6,190:193)], batters_advanced)
  
  # Dividing into test and train
  batters_train = batters_advanced[which(batters_advanced$playerid %in% batters_piselections),]
  batters_test = batters_advanced[which(batters_advanced$playerid %!in% batters_piselections),]
  
  # Logistic regression model
  set.seed(2020)
  batters_glm_advanced = train(
    form = Top100 ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + 
      PC11 + PC12 + PC13 + PC14,
    data = batters_train,
    trControl = trainControl(method = "cv", number = 10),
    method = "glm",
    family = "binomial"
  )
  
  # Model summary
  batters_glm_advanced
  # Model values
  batters_glm_advanced$finalModel
  
  # Test accuracy
  calc_accuracy_function(batters_test$Top100,
                         predict(batters_glm_advanced, newdata = batters_test))
  
  # Dataset measuring predictions vs accuracy
  batterscomp_advanced = cbind(batters_train$Name, predict(batters_glm_advanced, 
                                                              newdata = batters_train, 
                                                              type = "prob"), batters_train$Top100)
  head(batterscomp_advanced)
  
  # Confusion Matrix
  batters_cm_adv = confusionMatrix(predict(batters_glm_advanced, newdata = batters_test),batters_test$Top100, positive = '1')
  batters_cm_adv$table
```
## Advanced PCA & LR - Pitchers
Variables Included - Left on Base Percentage, Line Drive Percentage, Fly Ball Percentage, Ground Ball Percentage, Soft Contact Percentage, Medium Contact Percentage, Hard Contact Percentage, Batting Average on Balls in Play, Earned Run Average Plus, Fielding Independent Pitching, Expected Fielding Independent Pitching, Skill Interactive Earned Run Average, WAR (FG), game Leverage, Wins Above Average, Wins Above Average adjusted, Wins Above Average Win-Loss %, Full Season Win-Loss Percent, WAR (BR), Win Probability Added, Runs Expectancy Wins, player Leverage Index, Win Probability Added per Leverage, Clutch, Shutdowns, Meltdowns, All Star, Gold Glove, Silver Slugger, MVP Rank & Vote Points, Cy Young Rank & Vote Points, Rookie of the Year Rank & Vote Points
```{r advanced pitchers, cache = TRUE}
  # Selecting variables
  pitchers_advanced = pitchers_active[,c(24:49,50:54,57:58,61:62)]
  # PCA
  pca_pitchers_advanced = prcomp(pitchers_advanced, scale. = TRUE)
  summary(pca_pitchers_advanced)
  cbind(pitchers[1:6,1],pca_pitchers_advanced$x[1:6,1:6])
  head(pca_pitchers_advanced$scale^2, n = 6)
  # Assigning elements of variability to vectors
  PVE = summary(pca_pitchers_advanced)$importance[2,]
  CVE = summary(pca_pitchers_advanced)$importance[3,]
  
  # Graph of variability explained 
  PVEplot <- qplot(c(1:20), PVE[1:20]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("PVE - pitchers") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.1))
  PVEplot
  # Flattens out after the 16th PCA component
  
  CVEplot <- qplot(c(1:25), CVE[1:25]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("CVE - pitchers") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.2)) + 
    geom_hline(yintercept = 0.95, color = "red", lwd = 1)
  CVEplot
  # Reaches 95% cumulative variability after 21th component
  
  # Adding PCA Components and descriptive values back to dataset
  pitchers_advanced = cbind(pitchers_advanced, pca_pitchers_advanced$x[,1:21])
  pitchers_advanced = cbind(pitchers[,c(1:6,163:166)], pitchers_advanced)
  
  # Dividing into test and train
  pitchers_train = pitchers_advanced[which(pitchers_advanced$playerid %in% pitchers_piselections),]
  pitchers_test = pitchers_advanced[which(pitchers_advanced$playerid %!in% pitchers_piselections),]  
  
  # Logistic Regression Model
  set.seed(2020)
  pitchers_glm_advanced = train(
    form = Top100 ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11,
    data = pitchers_train,
    trControl = trainControl(method = "cv", number = 10),
    method = "glm",
    family = "binomial"
  )
  
  # Model summary
  pitchers_glm_advanced
  # Model values
  pitchers_glm_advanced$finalModel

  # Test accuracy
  calc_accuracy_function(pitchers_test$Top100,
                         predict(pitchers_glm_advanced, newdata = pitchers_test))
  
  # Dataset to compare predictions vs actual
  pitcherscomp_advanced = cbind(pitchers_train$Name, predict(pitchers_glm_advanced, 
                                                           newdata = pitchers_train, 
                                                           type = "prob"), pitchers_train$Top100)
  head(pitcherscomp_advanced)
  
  # Confusion Matrix
  pitchers_cm_adv = confusionMatrix(predict(pitchers_glm_advanced, newdata = pitchers_test), pitchers_test$Top100, positive = '1')
  pitchers_cm_adv$table
```

## Combining PCA Elements and then LR - Batters
Variables Included - all PCA elements from traditional and advanced logistic regression models
```{r combining pca batters, cache = TRUE}
  # Merging PCA elements to one dataset
  colnames(batters_traditional)[39:54] = gsub("PC", "PC_T", colnames(batters_traditional)[39:54]) 
  colnames(batters_advanced)[55:77] = gsub("PC", "PC_A", colnames(batters_advanced)[55:77])
  batters_trad_adv = cbind(batters_traditional, batters_advanced)
  # Getting rid of non-PCA columns
  batters_trad_adv = batters_trad_adv[,-c(32:38,55:64)] 
  batters_trad_adv = batters_trad_adv[,-c(11:31,48:91)]
  
  # Dividing into test and train
  batters_train = batters_trad_adv[which(batters_trad_adv$playerid %in% batters_piselections),]
  batters_test = batters_trad_adv[which(batters_trad_adv$playerid %!in% batters_piselections),]  
  
  # Logistic Regression
  set.seed(2020)
  batters_glm_trad_adv = train(
    form = Top100 ~ PC_T1 + PC_T2 + PC_T3 + PC_T4 + PC_T5 + PC_T6 + PC_T7 + PC_T8 + PC_T9 + 
      PC_T10 + PC_T11 + PC_T12 + PC_T13 + PC_T14 + PC_T15 + PC_T16 +
      PC_A1 + PC_A2 + PC_A3 + PC_A4 + PC_A5 + PC_A6 + PC_A7+ PC_A8 + PC_A9 + PC_A10 + 
      PC_A11 + PC_A12 + PC_A13 + PC_A14 + PC_A15 + PC_A16 + PC_A17 + PC_A18 + PC_A19 + PC_A20 +
      PC_A21 + PC_A22 + PC_A23,
    data = batters_train,
    trControl = trainControl(method = "cv", number = 5),
    method = "glm",
    family = "binomial"
  )
  
  # Model summary
  batters_glm_trad_adv
  # Model values
  batters_glm_trad_adv$finalModel
  
  # Test accuracy
  calc_accuracy_function(batters_test$Top100,
                         predict(batters_glm_trad_adv, newdata = batters_test))

  # Dataset to compare predictions v accuracy
  batterscomp_trad_adv = cbind(batters_train$Name, predict(batters_glm_trad_adv, 
                                                           newdata = batters_train, 
                                                           type = "prob"), batters_train$Top100)
  
  head(batterscomp_trad_adv)
  
  # Confusion Matrix
  batters_cm_trad_adv = confusionMatrix( predict(batters_glm_trad_adv, newdata = batters_test), batters_test$Top100, positive = '1')
  batters_cm_trad_adv$table
```

# Combining PCA and then LR - Pitchers
Variables Included - All PCA components from traditional and advanced logistic regression models
```{r combining pca pitchers, cache = TRUE}
  # Combining PCA columns to one dataset
  colnames(pitchers_traditional)[35:50] = gsub("PC", "PC_T", colnames(pitchers_traditional)[35:50]) 
  colnames(pitchers_advanced)[46:66] = gsub("PC", "PC_A", colnames(pitchers_advanced)[46:66])
  pitchers_trad_adv = cbind(pitchers_traditional, pitchers_advanced)
  pitchers_trad_adv = pitchers_trad_adv[,-c(26:34,51:60)] 
  pitchers_trad_adv = pitchers_trad_adv[,-c(11:25,42:76)]
  
  # Dividing into test and train
  pitchers_train = pitchers_trad_adv[which(pitchers_trad_adv$playerid %in% pitchers_piselections),]
  pitchers_test = pitchers_trad_adv[which(pitchers_trad_adv$playerid %!in% pitchers_piselections),]  
  
  # Logistic Regression
  set.seed(2020)
  pitchers_glm_trad_adv = train(
    form = Top100 ~ PC_T1 + PC_T2 + PC_T3 + PC_T4 + PC_T5 + PC_T6 + PC_T7 + PC_T8 + 
      PC_T9 + PC_T10 + PC_T11 + PC_T12 + PC_T13 + PC_T14 + PC_T15 + 
      PC_A1 + PC_A2 + PC_A3 + PC_A4 + PC_A5 + PC_A6 + PC_A7 + PC_A8 + PC_A9 + PC_A10 + PC_A11 + 
      PC_A12 + PC_A13 + PC_A14 + PC_A15,
    data = pitchers_train,
    trControl = trainControl(method = "cv", number = 5),
    method = "glm",
    family = "binomial"
  )
  
  # Model summary
  pitchers_glm_trad_adv
  # Model values
  pitchers_glm_trad_adv$finalModel
  
  
  # Test accuracy
  calc_accuracy_function(pitchers_test$Top100,
                         predict(pitchers_glm_trad_adv, newdata = pitchers_test))
  
  # Dataset to compare predictions v accuracy
  pitcherscomp_trad_adv = cbind(pitchers_train$Name, predict(pitchers_glm_trad_adv, 
                                                           newdata = pitchers_train, 
                                                           type = "prob"), pitchers_train$Top100)

  # Confusion Matrix
  pitchers_cm_trad_adv = confusionMatrix(predict(pitchers_glm_trad_adv, newdata = pitchers_test),pitchers_test$Top100, positive = '1')
  pitchers_cm_trad_adv
```

## Performing PCA on Traditional and Advanced then LR - Batters  
Variables Included - All traditional and advanced variables used in PCA 
```{r pca on combination batters, cache = TRUE}
  # Merging datasets
  batters_both = cbind(batters_traditional, batters_advanced)
  # Removing name, descriptive values and PCA
  batters_both = batters_both[,-(55:64)] 
  batters_both = batters_both[,-c(1:10,39:54,92:121)]
    
  # PCA
  pca_batters_both= prcomp(batters_both, scale. = TRUE)
  summary(pca_batters_both)
  cbind(batters[1:6,1],pca_batters_both$x[1:6,1:6])
  head(pca_batters_both$scale^2, n = 6)
  PVE = summary(pca_batters_both)$importance[2,]
  CVE = summary(pca_batters_both)$importance[3,]
  
  # Graph of variability explained
  PVEplot <- qplot(c(1:20), PVE[1:20]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("PVE - Batters") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.1))
  PVEplot
  # Flattens out after the 15th PCA component
  
  # Graph of cumulative variability explained
  CVEplot <- qplot(c(1:30), CVE[1:30]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("CVE - Batters") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.2)) + 
    geom_hline(yintercept = 0.95, color = "red", lwd = 1)
  CVEplot
  # Reaches 95% cumulative variability after 29th component
  
  # Readding pca and descriptive values back to dataset
  batters_both = cbind(batters_both, pca_batters_both$x[,1:29])
  batters_both = cbind(batters[,c(1:6,190:193)], batters_both)
  
  # Dividing into test and train
  batters_train = batters_both[which(batters_both$playerid %in% batters_piselections),]
  batters_test = batters_both[which(batters_both$playerid %!in% batters_piselections),]  

  # Logistic Regression
  set.seed(2020)
  batters_glm_both = train(
    form = Top100 ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + 
      PC11 + PC12 + PC13 + PC14 + PC15 + PC16 + PC17 + PC18 + PC19 + PC20 + 
      PC21 + PC22 + PC23 + PC24 + PC25 + PC26 + PC27 + PC28 + PC29,
    data = batters_train,
    trControl = trainControl(method = "cv", number = 5),
    method = "glm",
    family = "binomial"
  )
  
  # Model summary
  batters_glm_both
  # Model values
  batters_glm_both$finalModel
  
  # Test accuracy
  calc_accuracy_function(batters_test$Top100,
                         predict(batters_glm_both, newdata = batters_test))

  # Dataset to compare predictions with actual
  batterscomp_both = cbind(batters_train$Name, predict(batters_glm_both, 
                                                           newdata = batters_train, 
                                                           type = "prob"), batters_train$Top100)
  head(batterscomp_both)
  
  # Confusion Matrix
  batters_cm_both = confusionMatrix(predict(batters_glm_both, newdata = batters_test),batters_test$Top100, positive = '1')
  batters_cm_both$table
```

# Performing PCA on Traditional and Advanced, then LR - Pitchers
Variables Included - All traditional and advanced variables from PCA
```{r pca on combination pitchers, cache = TRUE}
  # Combining dataset
  pitchers_both = cbind(pitchers_traditional, pitchers_advanced)
  # Removing unnecessary variables
  pitchers_both = pitchers_both[,-(51:60)] 
  pitchers_both = pitchers_both[,-c(1:10,35:50,77:106)]
  
  # PCA
  pca_pitchers_both= prcomp(pitchers_both, scale. = TRUE)
  summary(pca_pitchers_both)
  cbind(pitchers[1:6,1],pca_pitchers_both$x[1:6,1:6])
  head(pca_pitchers_both$scale^2, n = 6)
  PVE = summary(pca_pitchers_both)$importance[2,]
  CVE = summary(pca_pitchers_both)$importance[3,]
  
  # Graph of variability explained
  PVEplot <- qplot(c(1:20), PVE[1:20]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("PVE - pitchers") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.1))
  PVEplot
  # Flattens out after the 15th PCA component
  
  # Graph of cumulative variability explained
  CVEplot <- qplot(c(1:30), CVE[1:30]) + 
    geom_bar(stat = "Identity") + 
    xlab("Principal Component") + 
    ylab("CVE - pitchers") +
    ggtitle("Scree Plot") +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.2)) + 
    geom_hline(yintercept = 0.95, color = "red", lwd = 1)
  CVEplot
  # Reaches 95% cumulative variability after 26th component
  
  # Adding PCA components and descriptive statistics back to dataset
  pitchers_both = cbind(pitchers_both, pca_pitchers_both$x[,1:26])
  pitchers_both = cbind(pitchers[,c(1:6,163:166)], pitchers_both)
  
  # Dividing into test and train
  pitchers_train = pitchers_both[which(pitchers_both$playerid %in% pitchers_piselections),]
  pitchers_test = pitchers_both[which(pitchers_both$playerid %!in% pitchers_piselections),]  
  
  # Logistic Regression
  set.seed(2020)
  pitchers_glm_both = train(
    form = Top100 ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + 
      PC11 + PC12 + PC13 + PC14 + PC15 + PC16 + PC17 + PC18 + PC19 + PC20 + PC21,
    data = pitchers_train,
    trControl = trainControl(method = "cv", number = 5),
    method = "glm",
    family = "binomial"
  )
  
  # Model summary
  pitchers_glm_both
  # Model values
  pitchers_glm_both$finalModel
  
  # Test accuracy
  calc_accuracy_function(pitchers_test$Top100,
                         predict(pitchers_glm_both, newdata = pitchers_test))
  
  # Dataset to compare predictions with accuracy
  pitcherscomp_both = cbind(pitchers_train$Name, predict(pitchers_glm_both, 
                                                       newdata = pitchers_train, 
                                                       type = "prob"), pitchers_train$Top100)
  head(pitcherscomp_both)
  
  # Confusion Matrix
  pitchers_cm_both = confusionMatrix(predict(pitchers_glm_both, newdata = pitchers_test), pitchers_test$Top100, positive = '1')
  pitchers_cm_both$table
```

## PCA Results 
```{r confusion matrix gather, cache = TRUE}
cmlist = list(batters_cm_trad$table, pitchers_cm_trad$table, 
              batters_cm_adv$table, pitchers_cm_adv$table,
              batters_cm_trad_adv$table, pitchers_cm_trad_adv$table,
              batters_cm_both$table, pitchers_cm_both$table)

get_confusion_matrix_function = function(cmlist){
  tablelist = list()
  for(i in 1:length(cmlist)){
    tablelist[[i]] = as.data.frame(cmlist[[i]])
    tablelist[[i]] = tablelist[[i]] %>% 
  mutate(goodbad = ifelse(tablelist[[i]]$Prediction == tablelist[[i]]$Reference, "correct", "incorrect")) %>%
  group_by(Reference) %>%
  mutate(prop = Freq/sum(Freq))
  }
  tablelist
}

cmlist = get_confusion_matrix_function(cmlist)
```

```{r batters cm trad plot, cache = TRUE}
batters_cm_trad_plot = ggplot(data = cmlist[[1]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") + 
  ggtitle("CM for Traditional Variables - Batters") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r pitchers cm trad plot, cache = TRUE}
pitchers_cm_trad_plot = ggplot(data = cmlist[[2]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Traditional Variables - Pitchers") + 
  theme(plot.title = element_text(hjust = 0.5))

```

```{r batters cm adv plot, cache = TRUE}
batters_cm_adv_plot = ggplot(data = cmlist[[3]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Advanced Variables - Batters") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r pitchers cm adv plot}
pitchers_cm_adv_plot = ggplot(data = cmlist[[4]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Advanced Variables - Pitchers") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r batters cm trad adv plot, cache = TRUE}
batters_cm_trad_adv_plot = ggplot(data = cmlist[[5]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
   ggtitle("CM for Traditional & Advanced PCA - Batters") + 
   theme(plot.title = element_text(hjust = 0.5))
```

```{r pitchers cm trad adv plot, cache = TRUE}
pitchers_cm_trad_adv_plot = ggplot(data = cmlist[[6]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Traditional & Advanced PCA - Pitchers") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r batters cm both plot, cache = TRUE}
batters_cm_both_plot = ggplot(data = cmlist[[7]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) + 
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Traditional & Advanced Variables - Batters") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r pitchers cm both plot, cache = TRUE}
pitchers_cm_both_plot = ggplot(data = cmlist[[8]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Traditional & Advanced Variables - Pitchers") + 
  theme(plot.title = element_text(hjust = 0.5))

```

```{r fig.height=14, fig.width=10}
library(cowplot)
plot_grid(batters_cm_trad_plot,
pitchers_cm_trad_plot,
batters_cm_adv_plot,
pitchers_cm_adv_plot,
batters_cm_trad_adv_plot,
pitchers_cm_trad_adv_plot,
batters_cm_both_plot,
pitchers_cm_both_plot, nrow = 4, ncol = 2)
```

```{r cm table}
tablelist =  list(batters_cm_trad, batters_cm_adv,batters_cm_trad_adv, batters_cm_both,
                  pitchers_cm_trad, pitchers_cm_adv, pitchers_cm_trad_adv, pitchers_cm_both)

cm_accuracy = rep(NA,8)
cm_sensitivity = rep(NA,8)
cm_specificity = rep(NA,8)
cm_pospredvalue = rep(NA,8)
cm_negpredvalue = rep(NA,8)

for(i in 1:8){
  cm_accuracy[i] = round(tablelist[[i]]$overall['Accuracy'],3)
  cm_sensitivity[i] = round(tablelist[[i]]$byClass['Sensitivity'],3)
  cm_specificity[i] = round(tablelist[[i]]$byClass['Specificity'],3)
  cm_pospredvalue[i] = round(tablelist[[i]]$byClass['Pos Pred Value'],3)
  cm_negpredvalue[i] = round(tablelist[[i]]$byClass['Neg Pred Value'],3)
}

cm_names = c("Batters Traditional PCA", "Batters Advanced PCA", "Mix of Batters Trad/Adv PCA",
             "Batters Trad/Adv then PCA", "Pitchers Traditional PCA", "Pitchers Advanced PCA", "Mix of Pitchers Trad/Adv PCA", "Pitchers Trad/Adv then PCA")

cm_table = as.data.frame(cbind(cm_names, cm_accuracy, cm_sensitivity, cm_specificity,cm_pospredvalue, cm_negpredvalue))
colnames(cm_table) = c("Method", "Accuracy", "Sensitivity", "Specificity", "Positive PV", "Negative PV")
library(kableExtra)
kable(cm_table)
```

## Penalized Regression Models
```{r batters traditional penalized, cache = TRUE}
library(glmnet)
 # Selecting variables
  batters_traditional = batters_active[,c(4:15,46:47,31,57:62,68:72,75:76)]
  batters_traditional = cbind(batters[,c(1:6,191:193,190)],batters_traditional)
  
  # Dividing into test and train
  batters_train = batters_traditional[which(batters_traditional$playerid %in% batters_piselections),]
  batters_test = batters_traditional[which(batters_traditional$playerid %!in% batters_piselections),]
  
  # Removing variables not in model
  train_dv = batters_train[,c(1:9)]
  test_dv = batters_test[,c(1:9)]
  batters_train = batters_train[,-c(1:9)]
  batters_test = batters_test[,-c(1:9)]
  
  # Penalized logistic regression model
  set.seed(2020)
  cv_10 = trainControl(method = "cv", number = 10)
  
  batters_traditional_plr_model <- train(form = Top100 ~ ., data = batters_train,
                               method = "glmnet", 
                               family = "binomial",
                               trControl = cv_10,
                               tuneGrid = expand.grid(alpha = 1,
                                                    lambda = seq(0.001,0.1,by = 0.001)))
  
  # Best lambda value
  batters_traditional_plr_model$bestTune

  # Coefficients at that lambda value
  round(coef(batters_traditional_plr_model$finalModel, batters_traditional_plr_model$bestTune$lambda),3)
  
  # Test data accuracy
  calc_accuracy_function(batters_test$Top100,
                         predict(batters_traditional_plr_model, newdata = batters_test, 
                                 s = batters_traditional_plr_model$bestTune$lambda))
  
  
  batters_train = cbind(train_dv[,1:9], batters_train[,1], batters_train[,2:29])
  colnames(batters_train)[10] = "Top100"

  # Dataset of predictions v actual
  batterscomp_plr_traditional = cbind(batters_train$Name, batters_train$Season,
                                     predict(batters_traditional_plr_model, 
                                     newdata = batters_train, 
                                     s = batters_traditional_plr_model$bestTune$lambda,
                                     type = "prob"), batters_train$Top100)
  head(batterscomp_plr_traditional)
  
  # Confusion matrix
  batters_cm_plr_trad = confusionMatrix(predict(batters_traditional_plr_model, 
                                                  newdata = batters_test, 
                                                  s = batters_traditional_plr_model$bestTune$lambda),
                                                  batters_test$Top100, positive='1')
  batters_cm_plr_trad$table
```

```{r pitchers traditional penalized, cache = TRUE}
library(glmnet)
 # Selecting variables
  pitchers_traditional = pitchers_active[,c(1:2,5:7,13:18,20:23,50:54,57:58,61:62)]
  pitchers_traditional = cbind(pitchers[,c(1:6,164:166,163)], pitchers_traditional)
  
  # Dividing into test and train
  pitchers_train = pitchers_traditional[which(pitchers_traditional$playerid %in% pitchers_piselections),]
  pitchers_test = pitchers_traditional[which(pitchers_traditional$playerid %!in% pitchers_piselections),]
  
  # Removing variables not in model
  train_dv = pitchers_train[,c(1:9)]
  test_dv = pitchers_test[,c(1:9)]
  pitchers_train = pitchers_train[,-c(1:9)]
  pitchers_test = pitchers_test[,-c(1:9)]
  
  # Penalized logistic regression model
  set.seed(2020)
  cv_10 = trainControl(method = "cv", number = 10)
  
  pitchers_traditional_plr_model <- train(form = Top100 ~ ., data = pitchers_train,
                               method = "glmnet", 
                               family = "binomial",
                               trControl = cv_10,
                               tuneGrid = expand.grid(alpha = 1,
                                                    lambda = seq(0.001,0.1,by = 0.001)))
  
  # Best lambda value
  pitchers_traditional_plr_model$bestTune

  # Coefficients at that lambda value
  round(coef(pitchers_traditional_plr_model$finalModel, pitchers_traditional_plr_model$bestTune$lambda),3)
  
  # Test data accuracy
  calc_accuracy_function(pitchers_test$Top100,
                         predict(pitchers_traditional_plr_model, newdata = pitchers_test, 
                                 s = pitchers_traditional_plr_model$bestTune$lambda))
  
  
  pitchers_train = cbind(train_dv[,1:9], pitchers_train[,1], pitchers_train[,2:25])
  colnames(pitchers_train)[10] = "Top100"

  # Dataset of predictions v actual
  pitcherscomp_plr_traditional = cbind(pitchers_train$Name, pitchers_train$Season,
                                     predict(pitchers_traditional_plr_model, 
                                     newdata = pitchers_train, 
                                     s = pitchers_traditional_plr_model$bestTune$lambda,
                                     type = "prob"), pitchers_train$Top100)
  head(pitcherscomp_plr_traditional)
  
  # Confusion matrix
  pitchers_cm_plr_trad = confusionMatrix(predict(pitchers_traditional_plr_model, 
                                                  newdata = pitchers_test, 
                                                  s = pitchers_traditional_plr_model$bestTune$lambda),
                                                  pitchers_test$Top100, positive='1')
  pitchers_cm_plr_trad$table

```

```{r batters advanced penalized, cache = TRUE}
 # Selecting variables
  batters_advanced = batters_active[,c(16:29,32:45,48:51,63:72,75:76)]
  batters_advanced = cbind(batters[,c(1:6,191:193,190)],batters_advanced)
  
  # Dividing into test and train
  batters_train = batters_advanced[which(batters_advanced$playerid %in% batters_piselections),]
  batters_test = batters_advanced[which(batters_advanced$playerid %!in% batters_piselections),]
  
  # Removing variables not in model
  train_dv = batters_train[,c(1:9)]
  test_dv = batters_test[,c(1:9)]
  batters_train = batters_train[,-c(1:9)]
  batters_test = batters_test[,-c(1:9)]
  
  # Penalized logistic regression model
  set.seed(2020)
  cv_10 = trainControl(method = "cv", number = 10)
  
  batters_advanced_plr_model <- train(form = Top100 ~ ., data = batters_train,
                               method = "glmnet", 
                               family = "binomial",
                               trControl = cv_10,
                               tuneGrid = expand.grid(alpha = 1,
                                                    lambda = seq(0.001,0.1,by = 0.001)))
  
  # Best lambda value
  batters_advanced_plr_model$bestTune

  # Coefficients at that lambda value
  round(coef(batters_advanced_plr_model$finalModel, batters_advanced_plr_model$bestTune$lambda),3)
  
  # Test data accuracy
  calc_accuracy_function(batters_test$Top100,
                         predict(batters_advanced_plr_model, newdata = batters_test, 
                                 s = batters_advanced_plr_model$bestTune$lambda))
  
  
  batters_train = cbind(train_dv[,1:9], batters_train[,1], batters_train[,2:45])
  colnames(batters_train)[10] = "Top100"

  # Dataset of predictions v actual
  batterscomp_plr_advanced = cbind(batters_train$Name, batters_train$Season,
                                     predict(batters_advanced_plr_model, 
                                     newdata = batters_train, 
                                     s = batters_advanced_plr_model$bestTune$lambda,
                                     type = "prob"), batters_train$Top100)
  head(batterscomp_plr_advanced)
  
  # Confusion matrix
  batters_cm_plr_adv = confusionMatrix(predict(batters_advanced_plr_model, 
                                                  newdata = batters_test, 
                                                  s = batters_advanced_plr_model$bestTune$lambda),
                                                  batters_test$Top100, positive='1')
  batters_cm_plr_adv$table
```

```{r pitchers advanced penalized, cache = TRUE}
library(glmnet)
 # Selecting variables
  pitchers_advanced = pitchers_active[,c(24:49,50:54,57:58,61:62)]
  pitchers_advanced = cbind(pitchers[,c(1:6,164:166,163)], pitchers_advanced)
  
  # Dividing into test and train
  pitchers_train = pitchers_advanced[which(pitchers_advanced$playerid %in% pitchers_piselections),]
  pitchers_test = pitchers_advanced[which(pitchers_advanced$playerid %!in% pitchers_piselections),]
  
  # Removing variables not in model
  train_dv = pitchers_train[,c(1:9)]
  test_dv = pitchers_test[,c(1:9)]
  pitchers_train = pitchers_train[,-c(1:9)]
  pitchers_test = pitchers_test[,-c(1:9)]
  
  # Penalized logistic regression model
  set.seed(2020)
  cv_10 = trainControl(method = "cv", number = 10)
  
  pitchers_advanced_plr_model <- train(form = Top100 ~ ., data = pitchers_train,
                               method = "glmnet", 
                               family = "binomial",
                               trControl = cv_10,
                               tuneGrid = expand.grid(alpha = 1,
                                                    lambda = seq(0.001,0.1,by = 0.001)))
  
  # Best lambda value
  pitchers_advanced_plr_model$bestTune

  # Coefficients at that lambda value
  round(coef(pitchers_advanced_plr_model$finalModel, pitchers_advanced_plr_model$bestTune$lambda),3)
  
  # Test data accuracy
  calc_accuracy_function(pitchers_test$Top100,
                         predict(pitchers_advanced_plr_model, newdata = pitchers_test, 
                                 s = pitchers_advanced_plr_model$bestTune$lambda))
  
  
  pitchers_train = cbind(train_dv[,1:9], pitchers_train[,1], pitchers_train[,2:36])
  colnames(pitchers_train)[10] = "Top100"

  # Dataset of predictions v actual
  pitcherscomp_plr_advanced = cbind(pitchers_train$Name, pitchers_train$Season,
                                     predict(pitchers_advanced_plr_model, 
                                     newdata = pitchers_train, 
                                     s = pitchers_advanced_plr_model$bestTune$lambda,
                                     type = "prob"), pitchers_train$Top100)
  head(pitcherscomp_plr_advanced)
  
  # Confusion matrix
  pitchers_cm_plr_adv = confusionMatrix(predict(pitchers_advanced_plr_model, 
                                                  newdata = pitchers_test, 
                                                  s = pitchers_advanced_plr_model$bestTune$lambda),
                                                  pitchers_test$Top100, positive='1')
  pitchers_cm_plr_adv$table

```

```{r batters both penalized, cache = TRUE}
# Merging datasets
  batters_both = cbind(batters_traditional, batters_advanced)
  # Removing name, descriptive values and duplicates
  batters_both = batters_both[,-c(39:48,86:92)]
  
  # Dividing into test and train
  batters_train = batters_both[which(batters_both$playerid %in% batters_piselections),]
  batters_test = batters_both[which(batters_both$playerid %!in% batters_piselections),]
  
  # Removing variables not in model
  train_dv = batters_train[,c(1:9)]
  test_dv = batters_test[,c(1:9)]
  batters_train = batters_train[,-c(1:9)]
  batters_test = batters_test[,-c(1:9)]
  
  # Penalized logistic regression model
  set.seed(2020)
  cv_10 = trainControl(method = "cv", number = 10)
  
  batters_both_plr_model <- train(form = Top100 ~ ., data = batters_train,
                               method = "glmnet", 
                               family = "binomial",
                               trControl = cv_10,
                               tuneGrid = expand.grid(alpha = 1,
                                                    lambda = seq(0.001,0.1,by = 0.001)))
  
  # Best lambda value
  batters_both_plr_model$bestTune

  # Coefficients at that lambda value
  round(coef(batters_both_plr_model$finalModel, batters_both_plr_model$bestTune$lambda),3)
  
  # Test data accuracy
  calc_accuracy_function(batters_test$Top100,
                         predict(batters_both_plr_model, newdata = batters_test, 
                                 s = batters_both_plr_model$bestTune$lambda))
  
  
  batters_train = cbind(train_dv[,1:9], batters_train[,1], batters_train[,2:66])
  colnames(batters_train)[10] = "Top100"

  # Dataset of predictions v actual
  batterscomp_plr_both = cbind(batters_train$Name, batters_train$Season,
                                     predict(batters_both_plr_model, 
                                     newdata = batters_train, 
                                     s = batters_both_plr_model$bestTune$lambda,
                                     type = "prob"), batters_train$Top100)
  head(batterscomp_plr_both)
  
  # Confusion matrix
  batters_cm_plr_both = confusionMatrix(predict(batters_both_plr_model, 
                                                  newdata = batters_test, 
                                                  s = batters_both_plr_model$bestTune$lambda),
                                                  batters_test$Top100, positive='1')
  batters_cm_plr_both$table
```

```{r pitchers both penalized, cache = TRUE}
  # Combining dataset
  pitchers_both = cbind(pitchers_traditional, pitchers_advanced)
  # Removing unnecessary variables
  pitchers_both = pitchers_both[,-c(35:44,71:79)]
  
  # Dividing into test and train
  pitchers_train = pitchers_both[which(pitchers_both$playerid %in% pitchers_piselections),]
  pitchers_test = pitchers_both[which(pitchers_both$playerid %!in% pitchers_piselections),]
  
  # Removing variables not in model
  train_dv = pitchers_train[,c(1:9)]
  test_dv = pitchers_test[,c(1:9)]
  pitchers_train = pitchers_train[,-c(1:9)]
  pitchers_test = pitchers_test[,-c(1:9)]
  
  # Penalized logistic regression model
  set.seed(2020)
  cv_10 = trainControl(method = "cv", number = 10)
  
  pitchers_both_plr_model <- train(form = Top100 ~ ., data = pitchers_train,
                               method = "glmnet", 
                               family = "binomial",
                               trControl = cv_10,
                               tuneGrid = expand.grid(alpha = 1,
                                                    lambda = seq(0.001,0.1,by = 0.001)))
  
  # Best lambda value
  pitchers_both_plr_model$bestTune

  # Coefficients at that lambda value
  round(coef(pitchers_both_plr_model$finalModel, pitchers_both_plr_model$bestTune$lambda),3)
  
  # Test data accuracy
  calc_accuracy_function(pitchers_test$Top100,
                         predict(pitchers_both_plr_model, newdata = pitchers_test, 
                                 s = pitchers_both_plr_model$bestTune$lambda))
  
  
  pitchers_train = cbind(train_dv[,1:9], pitchers_train[,1], pitchers_train[,2:51])
  colnames(pitchers_train)[10] = "Top100"

  # Dataset of predictions v actual
  pitcherscomp_plr_both = cbind(pitchers_train$Name, pitchers_train$Season,
                                     predict(pitchers_both_plr_model, 
                                     newdata = pitchers_train, 
                                     s = pitchers_both_plr_model$bestTune$lambda,
                                     type = "prob"), pitchers_train$Top100)
  head(pitcherscomp_plr_both)
  
  # Confusion matrix
  pitchers_cm_plr_both = confusionMatrix(predict(pitchers_both_plr_model, 
                                                  newdata = pitchers_test, 
                                                  s = pitchers_both_plr_model$bestTune$lambda),
                                                  pitchers_test$Top100, positive='1')
  pitchers_cm_plr_both$table

```

## PLR Results
```{r plr confusion matrix gather, cache = TRUE}
cmlist = list(batters_cm_plr_trad$table, pitchers_cm_plr_trad$table, 
              batters_cm_plr_adv$table, pitchers_cm_plr_adv$table,
              batters_cm_plr_both$table, pitchers_cm_plr_both$table)

get_confusion_matrix_function = function(cmlist){
  tablelist = list()
  for(i in 1:length(cmlist)){
    tablelist[[i]] = as.data.frame(cmlist[[i]])
    tablelist[[i]] = tablelist[[i]] %>% 
  mutate(goodbad = ifelse(tablelist[[i]]$Prediction == tablelist[[i]]$Reference, "correct", "incorrect")) %>%
  group_by(Reference) %>%
  mutate(prop = Freq/sum(Freq))
  }
  tablelist
}

cmlist = get_confusion_matrix_function(cmlist)
```


```{r batters cm plr trad plot, cache = TRUE}
batters_cm_plr_trad_plot = ggplot(data = cmlist[[1]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") + 
  ggtitle("CM for Traditional Variables - Batters") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r pitchers cm plr trad plot, cache = TRUE}
pitchers_cm_plr_trad_plot = ggplot(data = cmlist[[2]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Traditional Variables - Pitchers") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r batters cm plr adv plot, cache = TRUE}
batters_cm_plr_adv_plot = ggplot(data = cmlist[[3]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Advanced Variables - Batters") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r pitchers cm plr adv plot, cache = TRUE}
pitchers_cm_plr_adv_plot = ggplot(data = cmlist[[4]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Advanced Variables - Pitchers") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r batters cm plr both plot, cache = TRUE}
batters_cm_plr_both_plot = ggplot(data = cmlist[[5]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) + 
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Traditional & Advanced Variables - Batters") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r pitchers cm plr both plot, cache = TRUE}
pitchers_cm_plr_both_plot = ggplot(data = cmlist[[6]], mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(correct = "green", incorrect = "red")) +
  theme_bw() +
  labs(fill = "Quality of Prediction", alpha = "Proportion") +
  ggtitle("CM for Traditional & Advanced Variables - Pitchers") + 
  theme(plot.title = element_text(hjust = 0.5))

```

```{r fig.height=14, fig.width=12}
library(cowplot)
plot_grid(batters_cm_plr_trad_plot,
pitchers_cm_plr_trad_plot,
batters_cm_plr_adv_plot,
pitchers_cm_plr_adv_plot,
batters_cm_plr_both_plot,
pitchers_cm_plr_both_plot, nrow = 3, ncol = 2)
```

```{r cm plr table}
tablelist =  list(batters_cm_plr_trad, batters_cm_plr_adv, batters_cm_plr_both,
                  pitchers_cm_plr_trad, pitchers_cm_plr_adv, pitchers_cm_plr_both)

cm_accuracy = rep(NA,6)
cm_sensitivity = rep(NA,6)
cm_specificity = rep(NA,6)
cm_pospredvalue = rep(NA,6)
cm_negpredvalue = rep(NA,6)

for(i in 1:6){
  cm_accuracy[i] = round(tablelist[[i]]$overall['Accuracy'],3)
  cm_sensitivity[i] = round(tablelist[[i]]$byClass['Sensitivity'],3)
  cm_specificity[i] = round(tablelist[[i]]$byClass['Specificity'],3)
  cm_pospredvalue[i] = round(tablelist[[i]]$byClass['Pos Pred Value'],3)
  cm_negpredvalue[i] = round(tablelist[[i]]$byClass['Neg Pred Value'],3)
}

cm_names = c("Batters Traditional PLR", "Batters Advanced PLR",
             "Batters Trad/Adv then PLR", "Pitchers Traditional PLR", "Pitchers Advanced PLR", "Pitchers Trad/Adv then PLR")

cm_plr_table = as.data.frame(cbind(cm_names, cm_accuracy, cm_sensitivity, cm_specificity,cm_pospredvalue, cm_negpredvalue))
colnames(cm_plr_table) = c("Method", "Accuracy", "Sensitivity", "Specificity", "Positive PV", "Negative PV")
kable(cm_plr_table)
```

```{r sensitivity comparison, fig.height = 5, fig.width=8}
pca_sensitivity = cm_table[c(1:2,4:6,8),c(1,3)]
plr_sensitivity = cm_plr_table[c(1:6),c(1,3)]

vc_comparison_table = rbind(pca_sensitivity, plr_sensitivity)
vc_comparison_table$Type = rep(c("Traditional Bat","Advanced Bat", "Both Bat", "Traditional Pitch", "Advanced Pitch", "Both Pitch"),2)

vc_comparison_table$Method <- factor(vc_comparison_table$Method, levels = c("Batters Traditional PCA", "Batters Traditional PLR", "Batters Advanced PCA", "Batters Advanced PLR", "Batters Trad/Adv then PCA", "Batters Trad/Adv then PLR", "Pitchers Traditional PCA", "Pitchers Traditional PLR", "Pitchers Advanced PCA", "Pitchers Advanced PLR", "Pitchers Trad/Adv then PCA", "Pitchers Trad/Adv then PLR"))

vc_comparison_table$Sensitivity = as.numeric(vc_comparison_table$Sensitivity)

library(scales)
ggplot(vc_comparison_table, aes(x = Method, y = Sensitivity, fill = Type)) +
  geom_bar(stat = "identity", position = position_dodge()) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Comparison of Sensivity Across PCA and PLR Methods") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  scale_y_continuous(limits = c(0.5, 0.75),breaks = seq(0.5, 0.75, 0.05), oob=rescale_none) +
  scale_fill_brewer(palette = "Blues", direction = -1)
```






